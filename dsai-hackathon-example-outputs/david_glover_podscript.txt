We want to minimize that as well. I'll leave you to it. I'll get some feedback. I'll get some feedback. I'll get some feedback. Where is this microphone? That's PA. You can all hear me? You can, indeed. Principal cloud advocate. I'm a principal cloud advocate. I'm going to get you to pay attention. We're very lucky to have Dave from Microsoft. Dave is a principal cloud advocate. He specifically is the guy on top of Microsoft open AI. He's going to walk you through what open AI is. At the end of the presentation, we'll be handing out your guys' access cards. We'll take care of that after. Let's give a round of applause for Dave. 9 a.m. in the morning. On a Saturday. Welcome, everybody. It's a good time to be here on a Saturday morning. This is probably the first in person presentation I've done for three years. I realized that setting up the audio, I remember when we first went into pandemic mode. We had to go online with our presentations. It was amazing. Now I'm back in person. I think the audio is more complicated than it was when we got to virtual. My name is Dave Glover. I'm a cloud developer advocate. I work for Microsoft. I'm based here in Sydney. It's a nice way to walk into the morning. I'm not a cloud developer. I'm a cloud developer. I've been around at Microsoft for 30 years. As you can imagine, over that 30 years, there's been a huge number of changes. That have occurred. Actively involved in the beginnings of Windows. Internet, mobile. And seeing what we're doing around AI. It's an exciting time. I'm going to go back. I have seen people fall back on the stage. Before we start off. How many people here have played around with chat GPT? All right. That's kind of a thought. How many folks here are more erring on the developer technical side? Okay. Fine. I'm assuming the rest of you are business oriented folks. Would that be fair? Okay. Just a bit of a level set. You've all had a bit of a play around with chat GPT. That's pretty cool. How many folks have heard of Azure? Microsoft Azure? Okay. Great. If you haven't heard of Microsoft Azure, it's basically our cloud platform. Okay? And there is tokens. You'll be able to get on to the cloud platform. Soon enough. After the session. All right. Okay. I'm Dave Glover. You can connect to me on LinkedIn. I'm a Twitter user. I occasionally tweet. I've even got my email address there. So feel free to connect with me if you do have any questions. And I'll try and do my level best to connect. Okay. So. I think really all of us have seen across the news. Information about chat GPT. It's kind of become the new thing in town. And pretty, pretty much wherever you look. It's really captured the attention. And I think there's a lot of discussion going out, particularly in the media. Around what's going on around these. Large language models. It's really kind of captured. The attention. And I'm sure that you're probably familiar with the statistics, but I think it took about a week. For there to be about a million people signing up on open AI. And about two months to get to a hundred thousand. So it's really captured the attention of individuals. But of course it's capturing the attention of business. So I think that's really important. And I'm going to go back to the next slide. I'm sorry. I've got another, another. Another microphone. Apologies. Thank you. And looking to boost productivity. So, so there's two problems. What we're doing is consumers. But, and I suspect a lot of us here thinking about how we can help enable businesses. To become more productive and better customer services. Innovate and faster and things like that. And I think that's the next wave of innovation. So I think we're at an inflection point. We would been at a number of points throughout kind of human history. I would almost go back as far as what we saw with the printing press. Industrial revolution. Things like the microprocessor, how that river. Revolutionized our lives. The internet, of course. Mobile technology. And here we are already into this next wave of innovation. So that's very much. I think. In advanced models are really becoming the new compute platform. And I think that's why they kind of get to thinking around that. Okay. Sorry for the notes. I actually had my notes on my screen, but now I'm kind of showing my screen. The way. Alrighty. So just as a bit of a part of history. Around AI. Now I'm assuming that. I'm not going to go into the details of the AI. But for folk who kind of maybe for more of a business background. Maybe not so much. But the, maybe the main thing I want to point out is. GPT, chat GPT didn't just appear overnight. It's been over decades of research and breakthrough. So really going back to the fifties where. We were in the early fifties. And we really tried to mimic human intelligence. And again, if you think about what the compute capabilities were back then, that was pretty, pretty limited. And, but it really did spur on the first kind of early systems. Of. Expert systems, which tried to mimic. Human decision-making. So that's kind of where we were in the fifties. So very early starting. Then we kind of got onto machine learning and I suspect the more technical folk here. But we were in the early fifties. And we were trying to mimic the human intelligence. And we were trying to mimic the machine learning. And if you think about machine learning. You had a dataset and really what you're trying to do is kind of build an algorithm. Which approximated this data. So we'd learn from the data. And then you've got to use that algorithm to go and make predictions. The, the, the obvious example, everyone talks about is things like house prices. You've got a house. So the certain postcode. It's got a certain number of bedrooms, number of blues, number of car parks. And you've got to predict that. And then you've got to predict the price. And then you have to predict what the future house prices will be. So we would first predict that price. Then we go and use that, that algorithm to go and predict future house prices. That's the kind of thing where what we did a lot with machine learning. Okay. So then we've got onto kind of deep learning. And again, folks would be more technical. And involved in these. If you think about deep learning is being able to generate mathematical models. And then we've got to go and do deep learning. And then we've got to go and do deep learning in the human brain. And that was really what those are. And a huge advances there. If you think about like recognition, voice recognition, stuff like those. That we got to. And then we're out to where we are now. So if you think about that, that's. That's over Kelly. Like 70 years of. A serious amount of research, a lot of hardware. Software developments in that period of time to get to where we are with generative AI. And. The. Turns out people didn't do too much software engineering.
semantic understanding of what we're saying. And if you're not familiar what I mean by semantic, I understand it's kind of understanding the intent. And the example I like to use, previously, if you think back maybe a few generations, when we'd looked at search or connecting with systems, it was tend to be keyword based. And the lovely example I like to use is someone might type into a search engine, my dream wedding, my dream wedding dress might be an example. And if you just took keyword, well, you might think, well, this person's dreaming about a wedding dress. Well, they could quite possibly have been dreaming about a wedding dress, but probably what they meant is their ideal wedding dress. So it's understanding what the intent is of that query. And that's where a lot of the research has gone into. And that's where we get to a generative AI, where it understands the semantic meaning of a query or a prompt we are to talk about. And then it can respond back to us in human-like natural language. Now, I did use the word human-like, and I really want to emphasize, for particularly for folk who may be relatively new to this, is really emphasize that these are statistical models that are making predictions. They are not human. They are making predictions about what is going to be, what is the next likely word in a sentence? And that's kind of how they work. But we did want to get over the point that these systems, although they may appear incredibly clever, by no means human, they are models, mathematical models. Okay, so the next thing I want to talk about is what's going on with OpenAI and Microsoft. So there are two kind of distinct groups, and you're probably familiar with OpenAI, and I suspect that's probably why you're here today. But you may not necessarily be aware of the Microsoft relationship with OpenAI. So effectively what Microsoft and OpenAI as an organization are doing, we are collaborating on the development of advanced AI systems. So that's where it is. And what Microsoft is doing in this is that we're building out supercomputer infrastructure to enable those models to be able to be developed as well as to be executed. So that's kind of what that is. So there is a relationship, it's a collaborative relationship, in which we are working with that organization, providing infrastructure to build those models. And then what we're doing is we're taking those models and then we're deploying them into Azure. More importantly, more to the point actually, you have the ability to be able to take those models and deploy them into your Azure subscription. So imagine you're a bank, and you might say, look, I want to go and run this GPT model and I want to go and enable this model. Then I would go into my Azure subscription and say, I want the Text DaVinci 003 model. And I want to be able to use that inside my business. Then I would basically create an instance of that model inside my organization. And then I would do things, I'd work with that model. And all that data and all the prompts, all those things remain within the context of my subscription. So that's pretty much what's going on. And we are working with OpenAI and essentially four families of models which you can deploy into Azure. So there's GPT-3, which is kind of text prompt base. There's a chat GPT and previews of GPT-4 and they are more conversational based. And I'm going to show a demo of this. How many people here know what a prompt is? Okay, a fair number of you, great. Completions, chat completions. Okay, cool. I'm going to show you if you don't know. So we've got this whole world of conversational, which we call, typically referred to as chat completions. We've got Codex, which is generative AI for code. So if you're familiar and if you're a developer, you would have seen things like Copilot, GitHub Copilot for Visual Studio, Visual Studio Code, where it can kind of almost second guess what you're developing and help you. And then the fourth model is a thing called DALI. And DALI is a generative image. And again, I'm going to show you that. Again, how many folk have played around with Bing and used Bing image? Okay, cool. How many people have never used Bing before? Oh, out of that crowd. It's kind of interesting. I have to confess, I have not been, I tend to probably use Google, but I have tended to swing back to Bing. And it's actually been a really pleasant experience. Because of one, well, because of the generative AI that's been built into it. So you can go and do the whole AI-based queries and you get that fascinating information, as well as if you play around with it, you can also do generative images. So you can say, hey, look, go and create me an image based on blah. And I'm going to show you that. But that's kind of, it's interesting to see that there's been more traction around Bing. And I have actually got used to it. Amazing. Alrighty, okay. So as I mentioned, we're OpenAI and Microsoft are two distinct organizations. We're collaborating around advanced AI models. And we have Azure OpenAI services. You can deploy models into your tenant, into your subscription. And you can also tune these models. You might have, you might take a general model and you say, hey, look, I'm building out a system for medical or I'm building out a system for legal and I need to tune up for specific scenarios. So kind of reemphasizing just what I said before, we've kind of got the models I mentioned before. So we've got these prompts, we've got this conversational, we've got chat conversational prompting. And so you've got GPT 3.5, GPT 4 and chat GPT. Codex, which I've mentioned, which is around specialized models for building out coding. And we've got generative image models. Okay, so I've already mentioned prompts and I feel like I think everybody, pretty much everybody put up their hand around prompts. And these are the kind of the fundamental things that we're in a situation where we are now connecting and communicating with an AI model and natural language as a prompt. And it will respond back with a continuation. So we look over the, on the left-hand side, we've kind of got the simplest prompt from something like GPT 3. Yep, so we can say, hey, look, you can put in a sentence and it will come back with the next most likely, statistically likely model of what those next words will look like. So that's one here. So it said, write a tagline for an ice cream shop. And the most likely response came back was, we serve up smiles. The other thing about it, you will almost certainly have noticed that you go and put the same prompt in and you get a slightly different answer. And again, because it's a statistical model, it's using sampling across the most likely candidates of words that are gonna be coming back through as candidates to go and to communicate back. Okay, so then, so that's the basic prompts. We've got these kind of more chat oriented, so more of the kind of chat GPT where you can start kind of having more of a conversation. Hey, look, I'm having trouble setting up my Xbox. Response, hey, the response could be back. There are a few things you can try to troubleshoot. And the response, hey, look, fantastic. Wouldn't life be so easy if it was that easy. Thanks, that worked. Do you have any games recommended for a 14 year old? And you can go on. But you can kind of get the idea. And this is what's captured the attention of organizations because they can now start potentially communicating. They might have chatbots sitting on websites that are pretty basic. You can now start taking that whole concept of these kind of conversational chat and then really extend out there to make it a much better experience for customers. Codex is the example there. You can see this is, and I appreciate most of you aren't developers, but this one here is just creating a query inside it, a SQL server, which is a database. And you get back responses. And the DALI one over here on the right hand side is, hey, look, describe what you wanna play around with, what you wanna see. And then the DALI model will come back with an image based on your description, which is really awesome. Okay, now I'm not gonna spend too much time dwelling on this but just this is the reason I put on the slide here is this is what enterprise customers are using. And it's kind of useful for you to understand if you're particularly if you're a startup or something like that, and you're looking to sell into enterprise or into customers about what are they using? Because you typically need to be able to play into what they're using. And that's kind of fundamentally what's going on here. So I suspect a lot of you are using Office today and enterprise is obviously using Office out there. And what we're doing around things like OpenAI is we are enhancing Office. So you'll see that if you look around, you'll find various announcements around what's going with Office. Using OpenAI and using prompts to say, hey, let's kickstart this email or let's kickstart this proposal. I've got a right to this customer, whatever it might be. But you're gonna find a lot of these advanced AI models starting to play out into Office. Dynamics, if you're not familiar, it's really around business systems. And again, we're seeing that it could be things around sentiment analysis, understanding customer issues and things like that. And obviously there are a whole lot of partner solutions which you guys might play into. If you're not, again, not familiar around application platform.
platforms, customers tend to be using things like Power BI. What Microsoft is doing is that we're introducing these advanced AI models, these GPT-like models and GPT-4 into the application platforms that our customers are using because the customers want to be much more productive. To kind of give you an example, how many folk here have been into Excel and you know you need to go and make a pivot? You need to make a pivot of a whole set of data and you need to go and make a pivot chart. How many folk have done that? And every time you go into it, you're kind of like, how the heck do I do that pivot chart again? And where we're going to be, and I think I saw a great demo, which is like, create a pivot, you can type, create me a pivot chart of this data in this range, bang, it'll go off and do it or create the commands to go and drive Excel to do it. So those are the kinds of things where we fundamentally know what we want to do, but we don't do it that often and those are kind of where things like models are going to be able to help us. We also have a range of services out there around bot services, cognitive search, video indexing, great for things like call centers. So call centers typically want to be able to record conversations, then they want to be able to figure out what was said in those conversations, extract the text off those, and then they're going to be passing those models through search, through advanced AI to be able to query, figure out, summarize what's going on in those conversations. Next thing I want to talk about is what we call cognitive services. Now open AI lives in the world of this layer called cognitive services. And to kind of give you a bit of a sense of what cognitive services exist is we've got things like vision, so being able to figure out what an object is, vision might be things like understanding what's on a form and be able to extract information off a form. Really popular scenario, you might think that the world is all gone web, but customers are still grappling with lots of paperwork and they want to be able to automate that, grab the information off those forms, and then be able to do something interesting with it. Grain of speech, text to speech, speech to text, language, decision support, and really what the new kid on the block is is open AI, Azure Open AI service, to be more specific. And what we're seeing customers, they're joining up these scenarios, they're taking the call center example I mentioned before, grabbing the text, grabbing the speech, conveying it to text, putting it into search, using that search to go and augment a prompt for when they're doing things like prompt generation. And the very bottom layer down here, we're kind of at the fundamental layer, which is really around Azure machine learning. So hey, look, you're a data scientist or machine learning engineer, and you've got data sets, you want to be able to work with those and generate models to go and match those into those data sets. Okay, so the next thing we'll talk about is what is going on around responsible AI. Now I'm sure that we've all been around long enough, read around the web, and again, over a period of time, we've all seen examples where industries or organizations are using AI to try and be more productive. An example I'm going to pick on Microsoft examples, it's an easy one, there was a model which came, I think it was in 2016, called Microsoft Tay. Had anyone heard of Microsoft Tay? Few people have. So it was an experimental AI model. And it didn't take long for people to get onto that model and start to get spewing out hate speech. So things like that, or encouraging people to take their own lives or things like that. So the whole of scenarios where, and eventually I think was up for about a week, and then I think it got taken down. Other examples where, and I'm going to pick on police enforcement, particularly in the US. Now again, you might have seen examples where enforcement agencies have taken data sets, and I'm going to look at crime statistics to try and figure out where the hotspots are for crime and maybe where the next hotspot would be. Now of course, those data sets almost certainly had a bias in them. And those data sets, human biases, were often biased towards African American population and the US. And then you had a situation, of course, you're taking those bias data sets, and then going building a model on there, and you're effectively reinforcing those human bias. And that's what we're trying to guard against. So we have this initiative called Responsible AI. And it's an initiative that's been around for about five years, ready to kind of address. So we obviously had our own issues with things like T. But we also saw our customers having these issues where these models had biases in them, and then they were just reinforcing these biases in there. So there are basically six principles around Responsible AI. So we've got things like the data that goes into these models should be private, it should be inclusive across the whole section of society, not singling out a particular section of a population. It should be accountable, you should be able to figure out how this data set impacted on the decision by these models. Transparency understanding where it should be fair, kind of responsible and safe, again, kind of getting down to things like making sure that the data is being used, it's reliable, reproducible, etc. So that's what's driving this. And you'll see this conversation coming from Microsoft all the time around Responsible AI. In fact, we have tooling to make this much easier for organizations to work with. So for example, on the Azure OpenAI service, there is a Responsible AI layer in there. It's called a content filter. And basically, you can be talking into that service. And again, super applicable for enterprises. Entrepreneurs do not want folk to be building out solutions, and then suddenly having hate speech being spewed into their organization. So we look at content filtering, there are models there to look at what the content, what the prompts are going into Azure OpenAI service, making sure they're appropriate. And if they aren't appropriate, then you'll get back a response back to your application. But also making sure that the response back from the model is appropriate. And there's some guidelines in there for things like that. But that's what we're doing. We want to make sure that we're not, that enterprise customers and consumers for that matter, and in terms of Bing, are not having a bad experience. And no doubt you all saw when Bing first came out with AI enhanced search, of course, people pushed it and pushed it and pushed it to see what they could do. We knew that would happen. And we did a lot of work to make sure we're doing more work to mitigate against that. But fundamentally, what we've got, we've got the six principles of AI. In fact, if you check out that link at the bottom, you'll see a great document in that article there about why Microsoft's got on board with this whole focus around responsible AI. And we view it as an industry initiative, by the way. We want organizations to think about data when they're building out systems. And then on top of that, we've kind of got these building blocks to enable all this, enable these principles. So our governance rules, tracking, training policy. So you'll find there's a host of information. If you go searching for Microsoft responsible AI, you'll find there's cheat sheets, there's documentation, things that you need to be considering when you're going building out models and deploying systems. And we provide tools and processes. So if you're building out models inside Azure, the machine learning service, we implement tools like a responsible AI dashboard, which will help you through this process of ensuring that you're going to build models which are representative. Okay, so the next thing I want to talk about is, so I've talked about responsible AI. And the next thing I want to talk about is really around kind of trust. Because everybody worries about their data, how that data has been used. Doesn't matter from, you read it across the press, no doubt you've thought about it as well. So the thing that I most want to emphasize here is when you're using Azure OpenAI service, you create an instance of a model in your tenant on your subscription. And anything you do with that interaction with that model, that data for one is held in encrypted storage. But secondly, it's your data, we do not use your data to go and train models. So you might, for example, come along and tune a model, you might say, look, I want to go and tune it for medical, and you kind of come up with some prompts and responses, and you go and push those in to go and tune those models. We do not look at that data, we do not take that data to go and use it to go and enhance those models. So really, the emphasis is, it's your data. It's your models, you can go and fine tune them, and it's yours. And obviously, organizations care about compliance and enterprise and security controls and things like that. Okay, so next thing I want to talk about is not all things are OpenAI. That said, today we're at a GPT hack, and I'm kind of assuming that pretty much everything is going to be OpenAI. So these are kind of things like I need a general purpose model that helps multiple tasks. Well, that could be a good candidate. I need to generate human-like text, I need wrapper prototyping, I could use a model with a little training. Those are all great candidates. And
So those will be great candidates for open AI, but it's not the only game in town. And I can't emphasize more that organizations, they have lots of complex needs. I've already touched upon the call center, but the forms, they've got a whole different sets of data sets that are coming through and the need to be able to convert that into a format which is searchable, which can then be used for prompts and enhancing prompts and things like that. So you'll tend to see it's a range of AI that build up an overall solution. Okay, so I've kind of got some use cases. So these are kind of the top use cases, but not limited. So content generation would be the obvious one. So we've got call center analytics. So we want to be able to figure out what was the overall sentiment from a call, what were the key points, what were customers' concerns? So you can use those types of things. You might have like an online site with a bot and you want to be able to generate a great customer experience and have prompts and narrow the domain down of the data. So a great example would be insurance sector. Where you might want to find out, does my insurance policy, how many people, does my insurance policy cover this type of dentistry? I'm sure we've all done that on our health insurance policies. And we try to find out that. So if you're an enterprise, maybe you're an insurance company, you could start creating a bot which now understands a domain. So it's got information that's being trained about, about insurance policies that this company offers. And then that information can be used to augment responses back to customers. So you can really create very rich, domain-specific responses back into a customer, back to your customers. Summation, I've kind of mentioned. So of course, in our analytics, kind of touched upon that. Code generation, if you're a developer, it's almost magical sometimes. I have been a developer for a long time and I realized I'm actually probably a very average developer because it seems when I want to code something, the model already understands what I want to do. And which I find fascinating, just saves a fantastic amount of time if you're a developer and using these models. Semantic search, I kind of talked about before. These kinds of things to better understand the intent of what the question is, and then to be able to formulate a response back to that. Okay, we'll talk through that. Okay, so this is a bit of a scenario. So I've kind of touched on this already, but you think about as much as we'd love to get away from paper, paper stool rules. In fact, if you do lots of presentations, I always keep a paper copy with me. But obviously through COVID, in fact, I built a workshop based on COVID, unfortunately, we all ended up filling in paper forms. We all went to the pharmacy and filled out a paper form and we wondered why we're doing this online, but of course we had to respond pretty quickly, created a massive amount of paperwork and we filled in forms. And all those forms got sent off to the health department and of course there's some processing. So tons of examples in our day-to-day lives. So we've got a document library, these documents have been scanned in. We've got something called form recognizer, which you can go and describe the layout of the form and you can pick out data from those forms. And then we grab each section or the data or whatever it might look like. And then we can, in this case, here we go and put it into something called cognitive search. And cognitive search is smart enough to understand intent. So you can put all this content into there, you can effectively index these documents but also have intent-based searching in there. So you get a search index, you got the end user come along and say, I want to make a query and to find out, I don't know, what part of the population got the COVID jab in April. It could be something as simple as that. And then you go in into that search index, the search index would then go and grab that data, grab relevant data from the search index, augment the prompt that was put in there augment the prompt that was put in by the end user. What, how many people got their jabs in April and then come back with the prompt or read that prompt and then respond back to the end user. So that's the kind of round trip that we see with these types of scenarios. I've already mentioned the call center one. This example here, conversations being recorded, they get stored, they get converted to text. Then we use open AI to go into summation and then we can go into Power BI and go and look at the conversation trends and things like that. Yes, actually. I will dig those up. There are some lovely examples. I will dig those up, but yes, there are some good examples there with this pattern has been implemented. Okay, so we're just gonna do a quick comparison of models. I'm gonna jump through these steps. So the general view, if you're building up then use chat GPT as your kind of default. Get something working and then, and it's also one of the cheapest models. And then you may be able to downgrade to an even cheaper model if you want. But chat GPT is generally what we recommend for people to start with. It's more broadly available as well. If you're based in Western Europe, which obviously we're not, then the GPT 3.5 models are based in those countries. At the moment, to be clear, the models are based in the US and across Western Europe. Now, obviously you can expect over time those models to be made more broadly available to more data centers across the world. And that is important obviously for some organizations, government organizations do not want their data going offshore. And things like GPT 4 will improve those prompts. Okay, so where are we going? Okay, so customizing Azure OpenAI. So we've got your prompts, we've got your data. So I've talked about lots of ways in which you can get data from forms, from call centers, whole bunch of things like that, augmenting that and then running it past the model and then getting the model to respond back. Okay, so I'm just gonna go into a bit of stuff that I think probably most of you already know. So we've got, I'm just gonna talk about key terms. So we've got an email, and we want to be able to extract information from this email. So we've got the prompt. So this, the email itself is a prompt and we've got some context here. So we want to extract the email address from this email. And we've kind of got the completion. So we've got the context, we've got the prompt and we've got the completion. In this case here, the address, just Microsoft in the US. Next I wanna talk about is tokens. And you'll hear this discussion about tokens. The first time people started talking about tokens, I started thinking, what the heck is a token? It's pretty straightforward. It's just a word or typically a part of a word. And it's a way in which models can be more efficient with processing sentences. Whoops. So a token would just be like, I thought, in fact, thought would probably be broken down into multiple tokens. Platform again, would be broken down to multiple tokens. Almost think it like a syllable. It's not a syllable, but it's a certain size sentence. There is a formula for it. Okay, so the next I'm gonna do is a little demo just to kind of show you some of how these things work. Now, given that most folk here have played around with us, I'm gonna show two types of demos. I'm gonna do what's called a completions demo and a chat completion demo. Now, I apologize. A couple of these will appeal much more to the technical folk and some of the business folk will think, what on earth is he talking about? But I'll try and emphasize why I'm showing these demos. Okay, so the first demo I'm gonna go and show is the old happy birthday. So what I've got here is I've loaded up something called Azure OpenAI Playground. So the playground is a place in which you can start experimenting with prompts and chat and chat completions. And you can see that I can select models. So inside my subscription, I have a number of models that I've loaded up and I'm gonna use the DaVinci Model 3. And I'm just gonna post in here. And statistically, the most likely thing to come back from that would be, happy birthday to you, happy birthday, blah, blah, blah. Okay, so that's kind of what, that's the most likely thing that we're gonna hear back from this model, which is fine. So, but let's say we didn't really quite mean that. Let's say we meant, and what we're gonna do now is we're gonna set a bit more context and say, happy birthday to you and here's a great handbag gift idea. So now what we're doing is we're adding more context into that prompt. And I'm sure that again, if you've been playing around with this, you've like me have watched.
watched more YouTube videos than you care to admit about prompt engineering. It's become the next coolest thing. So in this example here, instead of getting back happy birthday to you, happy birthday to you, I'm now getting back the handbag is the perfect gift, perfect for occasion makes the great handbag gift. So you can now see that very simply what I've done is I've added more context and I'm getting a different response back from the model. In this case here, it's a detachable, you can read as much as I hopefully you get the general idea. Okay, now the next thing, which is really fascinating, and this is where the power of these models kind of come in, is you can say, I want you to act as something in this case, and if you think about it, in real life, if you wanted legal advice, or medical advice, or whatever, a marketing advice, you would typically go to a find a doctor, or you go and find a lawyer, you go and find somebody who has experience or has a context of medical information. And this is effectively what you're doing, you're setting, you're telling the model, so I want you to kind of behave a bit like a marketing assistant. So we'll come back over here to the playground. And I'm going to say as a marketing is act as a marketing assistant, as a marketing assistant, and write a marketing plan and a fun tweet for happy birthday to you. And here's a great handbag gift idea. And of course, the idea is your startup, and you've got these fantastic handbags. And but you have no marketing background. And this will kind of come back and give you a bit of a strategy. So that's fairly standard kind of strategy. But again, if you're a startup, you may have no idea where to start with these handbags. And you can see it's come up here with a fun tweet, what the fun tweet is says happy birthday to you make this special day even more special with a stylish handbag. So you can kind of see where we're getting to. So we're setting context. But we're now telling it I want you to kind of behave a bit like you're a marketing system. Okay, so hopefully that makes sense. The next one is, I'm sorry, this is going to get a little bit more technical for folk who aren't developers. But you may you may kind of recognize this what I'm going to set is I'm going to use what are called chat completions. And I'm going to set what's called a system message. So in the playground, I'm going to come across the chat. And I'm going to set what's called a system message. And we just save that away. So the system message that I set, so I did jump around quite quickly, is I'm going to say you're an assistant designed to extract entities. Now, if you're not a developer, you might think what the heck is an entity, entity in this case is name, company phone number. Just think about like that. And users will paste in a string of text and you respond with an entity extracting text as a JSON. Again, if you're not a developer, you will think what on earth is all this about. And then the prompt I'm going to put in is Hello, my name is Robert Smith. I'm calling from Contoso Insurance. And I'm interested in learning about this is my phone number. So what I'm going to do is going to paste into the prompt. And you'll see it's come back as post as a prompt. And it's now brought me back a JSON string. Again, it's brought back with the entity about this. Now, super useful if you're a developer and you want to better extract information into a more structured format, you can get that and pass it through your system. Now, so you can see what's going on. And I'm going to have a bit of fun and games. I'll see if I can. But hey, look, I practiced this last night. Hope I can get it back again. Now, what you're seeing in here is what's going on with messages. Now, again, more of a developer focus, but it's really important to remember, though these models when you're chatting to one of these models, you might think, heck, how does this model over here understand or remember what I was talking about? It might be kind of curious. I've typed in this. And then I've said, no, I want a bit more like this. And you're having a conversation. And you think, wow, how does this model remember what's going on? Well, it doesn't. What you're doing is that you're replaying that conversation back. So as the chat develops, you are then taking that chat, that conversation, and then replaying it back to the OpenAI model. And it's coming back. So OK, this was a previous chat. I understand where we got to. This is the additional question. I'm going to respond back like that. Super important to remember, these models do not remember state. They do not remember the conversation. The other thing that you can do is you can click on View Code. So the playground, what it would do is it will give you sample code as to how to go and implement this conversation inside your application. So again, if you're Python developers, there's JSON, there's C Sharp, or you can even go and use curl if you're more technical folk. But you will get code examples back here in C Sharp, et cetera. Well, hey, look, I didn't remember. OK, so super important to remember, models are stateless. You are having to replay chats back to these things. And you can go into these playgrounds, and you can use and you can see great examples here of how these things hang together. I forgot to show that in the previous example here. You can go and look at and get the code samples for this. OK, the next one I'm going to show is an example that I first saw. And I unashamedly stole this demo from a YouTuber on the internet. And some of you may have seen this. And I thought, I remember seeing, I remember watching this demo thinking, huh, how does this demo work? And it really got me scratching my head thinking about I really don't get it. So in this case here, what I'm asking the chat GPT model is I want it to behave like a SQL server. Now, I appreciate that folk with more of a business bent will think what the heck is a SQL server? SQL server is a database systems. They keep records, customer records, all those types of things. They're held in there. So it's a technology which is used to store information about what's happening inside a business. So a bit like I said before, I just a marketing assistant. What I'm going to do is I'm going to tell the model to imagine that you are now a Microsoft SQL server. And this is a demo. So I've told it that. And we'll just clear up the chat. Has anyone seen this demo before? Someone down here. So I'm glad I fessed up to that I did. That I did make the demo. And I remember this is one of the first demos that came out. And apologies, this may be a little bit on the small side. But what I've put in here, as I said, you're going to execute a command about who am I. And it's going to respond back your domain user, which is and remember, this is not a database server. It has been trained on a whole corpus of documentation, including SQL server documentation manuals, discussions about this. So that's how this is working. What I'm going to say is I'm going to say exec, exec SB databases. And we're going to put on that. And remember, there's this replaying this chat. And it's come back here and I should get back. Okay, look at that, because it's non determinative. We're going to run that command again and see what happens. Okay, it's decided that it's not going to play quite like I wanted. So what I'm going to do is I'm going to create a database. And the response back, the model would be back, it would respond back, complete, completely successfully. Now, what I'm going to say is I'm going to say I'm going to use this customer database. And the most likely response back from this model would be the database context has changed the customer. And then what I'm going to do is I'm going to create a database table. Come in here. And commands completed successfully. Remember, this is not a database server, it's behaving like one though. And then I'm going to say select from users. And there will be no data in there. It's an empty data set. What I'm going to do is I'm going to put in a user. So again, if you're a database person, you would have understood this, I'm going to do an insert into that database. And then what I'm going to do is I'm going to come back over here and I'm going to say select star users. Paste that in. And with a fair win, you'll see you get back what you would get expect to get back from a database server. Let's go and paste in Dave. Dave has not been 30 for a while. But we'll paste that in. And we'll come over here and I will go and do things like come over here, select from users where name equals Dave. Run that query and voila, it brings back just Dave that row. So I want to emphasize this is not a database server. This is bringing back the most likely prediction based on the training corpus that is seen when the model was trained
out. But what I wanted to get across these demos is context matters, and particularly telling it who you want it to behave as or what do you want to behave as. So as I said, I saw that demo the first time I remember thinking, I am completely confused. What is going on here? Okay, not the first time in my life. Right. Go through that. Okay, so next thing I want to show is DALI. And I'm just going to go into DALI. And what I'm going to do is I'm going to, again, how many folk here played around with DALI? A reasonable number of you. Okay, so what we're going to do is we're going to go into a favorite search engine. And we're going to go into it's funny, it's not quite what I was expecting it to go to. Okay, what I did is I clicked on chat. So what it's going to do is I've tried it, I actually use this, I've been out for dinner at a friend's place. And I was to create a superhero cook in the style of pop art. And what the model will go off and do is create these. Now I just ran a campaign. It was a kind of content campaign. And I use I'm going to show you how I used it. So while it's off generating, we'll come over here to assets, and I created a whole lot of superheroes. And I had basically daily posts, and I wanted to kind of mix it up, I cannot draw to save myself. But I can type in text and I said create me an AI superhero. And you can see what I did, I wanted diversity, so different ages, different skin colors, different identities, all those types of things. But you can do that within these models, you can kind of nudge them to do what you want. And you'll see this kind of come back. And if I go and click on these, and you can get some this one here looks like a superhero cook. And you can see these are kind of things you can have a lot of fun with. So I've been using it now go for dinner, I always like learn, thank you very much for having us text back to these friends. And nowadays, what I do is I include a little superhero cook or something like that. It's just something to kind of mix it up a bit. Super easy to do, it doesn't cost anything. And you can have a lot of fun. But also, you can obviously use these in your applications. I've created some funny things around here, around superheroes, but as much as your imagination can take you. Right, okay, we are getting the end of it. Okay. Couple slides at the end. Okay, first of all, and I kind of think I started the talk with us, do not humanize AI. We strongly it is not human. These are these are models. They're using statistical models, and they're making predictions what the next likely word or next likely token will be. So they are not intelligent, they have the appearance of being so. But they're not, they are models. They're not deterministic. All you've probably seen, you've probably all seen this, you can put a same prompt in and you get back a different response. They're sampling back the most likely candidates for the next tokens that are going to come back through the next likely in terms of text and speech. They're also not trustworthy. Now, then, and I'm going to talk about that, what I mean by that. Now, you can kind of split this out into low risk scenarios and high risk scenarios. So a low risk scenario might be something like you build a chatbot, and you want to automate with AI and a customer's come in and they want to know more about a product. And let's say it gets it wrong, it will be annoying, but life is not going to finish. The other type of AI is what we call kind of like high risk scenarios. And in this kind of scenario, we talk more about collaborating with AI. Now, a scenario might be you've gone to the doctor, and the doctor has written your referral. Now, that doctors or that patient management system might be open AI enabled, and you might look at the type of symptoms or that type of thing. And it's generated referral later. Now, that's a great example where a doctor would want to collaborate with that response. And we'd hope the doctor would collaborate, they would use their expertise and say, okay, yeah, that looks fine. Actually, that may be that needs to be changed, etc. So think about your scenarios as high risk and low risk and what you think you can do, you can get away with, you know, what you can do to make it work. And then you can do what you can get away with. Automate, automate with AI, low risk scenarios, high risk scenarios, collaborate with AI is generally the rule of thumb. Okay, how to mitigate against hallucinations. Have we, has anyone heard of this kind of hallucinations? So again, we try not to humanize these things. And kind of we talk about hallucinations tends to be more of a human concept. And the other concept, which is quite becoming more popular, though I think it is also humanized, is confabulation. So I struggle to say the word. Basically, the model starts generating stuff that really doesn't make sense. And it's like talking to somebody who might be in another space for whatever reason, and you're communicating with them, and they're responding back to ways which which is just kind of out of context, or not in the way that you expect them to respond back. And models can respond back like that. But there are things that you can do, and particularly around tuning of models. You might say, like the medical one or the legal, where there is jargon and that where you want to be able to nudge these models into performing the way that makes sense for legal, for legal or medical terminology. I mentioned already around responsible AI. But there was also content filtering. So remember, I said, we don't want these systems to be spewing back hate speech, telling people to go and end their lives or whatever those things, we do not want folks to do that. So there are models in there that look at the responses going into these open AR models, and the responses coming back from them. Okay, so that's pretty much the talk. I've included a list of resources here. So you might want to you might want to pop a photo of the slide. But and I will go to I'll go through some of these. Now there's the documentation for open AI, Azure OpenAI service is excellent. And what you'll find is it's not difficult to get your head around what is going on. So there's the OpenAI services documentation. And I said, it's a manageable set of docs, you're not having to read war and peace. There's another set of learning modules out there called gets get started with Azure OpenAI service, developing, developing AI solutions with Azure OpenAI. And there's a great learning module there on data privacy and security. And also I recommend if you want to know more about how do these generative models work, then check out a colleague of mine, just go look out for search how generative a language models work. And there's a great document there which goes through more detail than what I've gone through on. Now, we've also got some documentation from what we call the AI business school. So this might be more interesting if you're kind of more business oriented, and you're wanting to understand and have information to help you take you through the process of maybe a startup, all those kind of things you need to be thinking about as a business person to go and build out an AI solution. So just go search for AI business school. And again, I actually think I probably captured most of this information on the previous slide, and I'll make these slides available to you guys as well. So you can get access to this. Alrighty, so that is pretty much the talk. So hopefully you kind of got a bit of a sense of what's going on. Main things I want to get across was things like responsible AI, super important, particularly to our customers, who are going to be building solutions around these things. Remember, context counts, so you can do more. What we try and encourage customers to do is to get smarter around prompts, do more with prompts before you start fine tuning. It can be super, we find customers that say, my scenario is so specific, I need to fine tune. Fine tuning tends to be more expensive. The models tend to be more expensive to run, whereas often it can be done with smarter prompts. So keep that in mind, to think, oh, I've got to do fine tuning. My scenario is so specific. You remember, you can augment the prompts with data which might be coming out of backend systems, so search systems, database systems, vector databases, all these types of places where you can get data. So you can augment what you're doing out of there. And I think that's pretty much, I talked about use cases. Yeah, alrighty, so that's pretty much the talk. Are there any questions? Go for it. You've done finding
So the question was, will I join your team? I won't join your team, but I am gonna be around for a few hours and I'm super happy to sit down with all of the teams and just talk through each of the scenarios. Okay, go for it, another question. Is this accessible to tiny startups as it involves like business? Is this at all where it's just gonna be a piracy algorithm or something where you could launch? Okay, that's a great question. So the question was, I think you are the mic, so the question was, is this available for startups? We have a whole program dedicated to startups. And if you go searching for Microsoft for startups and launch with AI, and we have a whole program which includes resources, access to compute time, models, et cetera, that are geared for startups. So go search out for Microsoft for startups. What we've given, what we've got today is we've got tokens, but they are a limited time, but you can go and sign up for Microsoft for startups program. You join something, I think it's called the Founders Hub. And inside that you'll get a whole stack of information, but also resources. So absolutely, we want startups to get on board with this. Yeah. Besides that as well, I've used Microsoft to create a really good, one of the Microsoft products, it's an awesome. Yeah, it's an awesome. Yeah, I'm just gonna change my glasses. Can I put on my, this is where I've come from. When I had, in doing everything virtual, I had the same focal distance. It was all great. It was all easy. Go for it. Yeah, so I've got a question. What would Azure AI's point of differences in response to Amazon's security extension by solution? Sorry, I really can't comment on that. I just don't know. So that is for you to find out and come and tell me. So what I would say is that Microsoft is very focused on enterprise customers. That's fundamentally where our sweet spot is. Okay, so I'd say that. And then what enterprises want, they want enterprise grade security and they want all the things that enterprise customers want around audit, assurance, governance, all those types of things. That's what enterprise customers want. And that's where we operate. I honestly cannot tell you anything about AWS's solution, but when you find out, please come and tell me. Yeah, so is this after Amazon App Assurance launch with- Is what, sir? Is it available for students? Is it available for students? Absolutely, yes. We have, the program is called, it's probably cunningly called Azure for Students. Just gonna set you around. If you're a student, so if you're a student for here, for example, most students will already have access to Azure. They can get it as part of university programs. If you're talking about university students, they will already have access to it. They can sign up for Azure. They do not require a credit card. They get a certain amount of credit. I think it's on the order of $250 US. I think it's on that kind of range to use all the services, range of services. I actually made a general demo of the launch for non-Azure. Yes, you can, yes. So you can just take a pre-paid Azure and then send it to the website. Yes, there's nothing to stop. Your child at home wants to play around with this, creating a subscription and getting on board with it. Correct. Yep. Well, I'll take one more. Is anyone else with a question? All right. All right. Let's give it up for Dave. I think we're running out of time. Anyone? Dave, would be helpful to share the links in the end? Yes. We can just, yeah, we can put it in the notion. We'll put it in the- Yeah, if you just, we'll get that from you. Yeah. Okay, so those are the important, very important, we covered the broad range of the sort of the enterprise use cases and how they decided on the Azure OpenAI service. Where we're going to go from here is, I would like the team to come visit us at the table in the corner. We're going to be handing out active schemes and get active people created for the team. So, the team can come to the corner, the table in the corner, and we'll be handing out an active for that. That's it, yeah. I'm going to send these to the corner there. And the cord or one of you who are there were asking me to come to the orbit. Thanks, Seth. Thank you. Thanks, Seth.